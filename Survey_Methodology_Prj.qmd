---
title: "Survey Methodology Group Prj"
format: html
editor: visual
---

## Final Assignment

## Libraries

```{r, message = FALSE}
rm(list = ls())

library(haven)
library(tidyverse)
library(naniar)
library(visdat)
library(mice)
library(GGally)
library(corrplot)
library(randomForest)
library(ggcorrplot)
library(reshape2)
library(readr)
library(caret)
library(dplyr)
library(ggplot2)
library(viridis)
library(MASS)
library(lme4)
library(sjPlot)
library(tidyr)
library(patchwork)
library(car)
library(nnet)
```

```{r, results='hide'}

```

## Data uploading

```{r, message = FALSE}
data <- read_dta("data_cleaning_files/ZA7575.dta")

edueco_data <- read_csv("data_cleaning_files/UNESCO Edu Country Data 2019/edueco_data.csv")

trans_health_data <-read.csv("data_cleaning_files/trans_health_data.csv")

ilga_data <-  read_csv("data_cleaning_files/ilga_data.csv")
```

## DATA CLEANING

Cleaning specific variables to determine which are the more important ones for our analysis.

```{r}
data_clean<- data %>%
  mutate(across(where(is.labelled), as.numeric))

data_clean <- data_clean |> 
 select(where(is.numeric))|>
  select(-c(edition,studyno1, studyno2,survey, caseid, uniqid))
```

### Handling missing data

```{r}

total_missing <- sum(is.na(data_clean))
cat("Total Missing:", total_missing, "\n")

missing_per_column <- colSums(is.na(data_clean))

missing_df <- data.frame(Variable = names(missing_per_column), 
                         Missing_Count = missing_per_column, 
                         Missing_Percentage = (missing_per_column / nrow(data)) * 100)

missing_df <- missing_df[order(-missing_df$Missing_Percentage), ]
print(missing_df)


high_missing <- missing_df[missing_df$Missing_Percentage > 50, ]
print(high_missing)
```

In general, there are **2,506,136 missing values** in the data set.

Also, The output of the code shows the names of the columns (`p6mt`, `p13mt`, `p6cy`, etc.) and the corresponding counts of missing values for each. For instance, the column `p6mt` has 26,943 missing values.

```{r}

high_missing_vars <- names(missing_per_column[missing_per_column >50])

data_clean <- data_clean[, !(names(data_clean) %in% high_missing_vars)]

constant_vars <- names(Filter(function(x) length(unique(x)) == 1, data_clean))
data_clean <- data_clean[, !(names(data_clean) %in% constant_vars)]

```

First, we identified and removed columns that had more than 50% missing values. Columns with a high percentage of missing data can negatively affect the quality of analysis, so they were excluded from the data set. This was achieved by creating a list of columns where the missing data percentage exceeded 50%, and then filtering out these columns from the `data_clean` data set.

Next, we removed constant columns, which are columns where every value is the same across all rows. These columns do not provide useful information for analysis because they lack variability. To identify constant columns, we checked each column for the number of unique values and filtered out those that only had one unique value. This step ensures that the data set contains only columns that offer meaningful variation and are more useful for analysis.

### Formatting and more…

```{r}

numeric_data <- data_clean[, sapply(data_clean, is.numeric)]

# Identify constant columns (standard deviation = 0)
zero_sd_vars <- sapply(numeric_data, function(x) sd(x, na.rm = TRUE) == 0)

# Remove constant columns
numeric_data <- numeric_data[, !zero_sd_vars]

# Compute the correlation matrix
cor_matrix <- cor(numeric_data, use = "pairwise.complete.obs")

high_cor <- findCorrelation(cor_matrix, cutoff = 0.90) 

filtered_data <- numeric_data[, -high_cor]

```

First, we created a subset containing only the numeric data. This was achieved by selecting the numeric columns from the `data_clean` dataset using the `sapply()` function. As a result, we created a new data set (`numeric_data`) that contained only the numeric columns. We did this because we wanted to focus on the variables that are relevant for numerical analysis and exclude any non-numeric columns that could complicate the process.

Next, we identified constant columns. Constant columns are those where all the values are identical, and they do not provide any useful variation for analysis. We calculated the standard deviation of each column, and if the standard deviation was 0, it indicated that the column was constant. These columns were flagged and removed from the data set. We performed this step because constant columns do not contribute to the variability in the data and could distort the results of the analysis. Removing them ensured that only meaningful columns remained in the data set.

Afterwards, we examined the correlation between the columns in the numeric data set. Correlation measures the relationship between two variables, and highly correlated columns can cause multicollinearity in modeling. We used the `cor()` function to compute the correlation matrix, with the `use = "pairwise.complete.obs"` argument ensuring that only complete pairs of observations were used, ignoring any missing values. This step was necessary to understand how the variables relate to each other and to avoid issues that arise from highly correlated features.

We then identified columns with high correlation, specifically those with a correlation coefficient greater than 0.90. These columns were selected using the `findCorrelation()` function. We performed this step to remove redundant information and avoid the problem of multi collinearity, where highly correlated variables can distort the results of regression models and lead to less reliable interpretations.

Finally, we removed the highly correlated columns from the data set. Since `high_cor` contained the indices of the highly correlated columns, we excluded those columns from the `numeric_data` dataset. The resulting data set, named `filtered_data`, now contains only the variables that are relevant and not highly correlated. This step was crucial to ensure that we had a data set with distinct and useful features for further analysis.

### Imputation

```{r}
 # List of different imputation methods to test
method_list <- c("pmm", "rf", "cart")

# Store the imputed datasets
imputed_datasets <- list()

for (method in method_list) {
  cat("\nRunning:", method, "...\n")
  
# Perform imputation using the selected method
  imputed_datasets[[method]] <- mice(data_clean, method = method, m = 3, maxit = 3, seed = 123)
}

```

In this code, we are testing different imputation methods to fill in missing values in the data set `data_clean`. Imputation is the process of replacing missing data with substituted values, and different methods can be tested to see which one works best for the data set. The three imputation methods chosen for testing in this code are `"pmm"`, `"rf"`, and `"cart"`.

**PMM**: Predictive Mean Matching, a method that uses regression models to impute missing values based on similar observed values.

**RF**: Random Forest, a machine learning algorithm that can be used to predict missing values based on the relationships between other variables in the dataset.

**CART**: Classification and Regression Trees, a decision tree method that can be used for both classification and regression tasks, and it is also effective in imputing missing data.

After we defined the list of imputation methods, the code then loops through each of these methods one by one to apply them to our dataset. For each method, a message is printed to let us know which method is currently being used. This makes it easier for us to follow the process, especially when we are running multiple methods.

Then, for each method, the imputation is performed on the `data_clean` data set. Imputation is the process of filling in the missing values with estimates based on the existing data. For each method, the code creates three different versions of the data set, each with the missing values filled in a slightly different way. These multiple datasets help to ensure that the imputed values are reliable and not just based on one estimation.

To make the imputation process more accurate, the method is run three times for each data set. This means that the imputation is refined over three cycles to get better results. By repeating the process, we can be more confident that the filled-in values are close to what the actual values might have been.

Finally, after performing the imputation for each method, the resulting datasets are stored in a list. This list allows us to keep track of which imputed data set came from which method. Each method’s datas et is labeled by the name of the method, so we can easily compare the results later on to see which method worked best for our data set.

### title?

```{r}
data_comparison <- data.frame(
  Original = as.numeric(numeric_data[["qc19"]]),  # Original before imputation
  PMM = as.numeric(complete(imputed_datasets[["pmm"]])[["qc19"]]),  
  RF = as.numeric(complete(imputed_datasets[["rf"]])[["qc19"]]),  
  CART = as.numeric(complete(imputed_datasets[["cart"]])[["qc19"]])  
)

plot_data <- melt(data_comparison, 
                  variable.name = "Method", value.name = "qc19_values")

```

The first part of the code creates a new dataset called `data_comparison`, which is used to compare the original data (before any imputation) with the imputed values. This dataset includes the `qc19` column from the original data and the imputed values from three different methods (PMM, RF, and CART). Each method’s imputed values are extracted from the imputed datasets we generated earlier and added to the comparison table. The purpose of this is to visually compare the original data with the different imputation methods to see how the imputed values differ.

Then, we use the `reshape2` library to transform the data into a format suitable for plotting. The `melt()` function is used to convert the data into a "long format," where each row represents a value from one of the imputed datasets, along with the method used. The new column called "Method" stores the method names (PMM, RF, and CART), and the column `qc19_values` stores the values for the `qc19` column from each dataset

```{r}
# Plot 
 ggplot(plot_data, aes(x = qc19_values, fill = Method)) +
  geom_histogram(binwidth = 1, alpha = 0.6, position = "identity") +
  facet_wrap(~Method, scales = "free_y") +  # Separate plots for each method
  labs(title = "Comparison of Imputation Methods",
       x = "qc19 Values", y = "Frequency") +
  theme_minimal()
```

**Comparison of Imputation Methods for qc19**

**(Interpretation)\
**This graph compares the distribution of qc19 values across different imputation methods (PMM, RF, CART, LogReg, PolyReg) and the original dataset.\
The distributions in each subplot look quite similar, suggesting that the imputed data preserves the original pattern well.\
Some imputation methods may introduce subtle differences, particularly in the frequency of certain qc19 values, which can be seen in slight variations in bar heights.

## Distribution

```{r}
data <- data %>%
  mutate(qc19 = as_factor(qc19),
         gender = as_factor(d10))

qc19_country_gender_dist <- data%>%
  group_by(isocntry, gender, qc19) %>%
  summarise(count = n(), .groups = 'drop')

```

```{r}
ggplot(qc19_country_gender_dist, aes(x = qc19, y = count, fill = gender)) +
  geom_col(position = "dodge", width = 0.7) +  # Dodge to separate gender groups
  facet_wrap(~isocntry, scales = "fixed") +  # Fix the y-axis across all countries
  scale_fill_manual(values = c("Man" = "#3C8BFA", "Woman" = "#663CFA")) +  # Gender colors
  scale_y_continuous(limits = c(0, 400), oob = scales::squish) +  # Set y-axis range and clip outside values
  labs(title = "Distribution of qc19 Responses by Country and Gender",
       x = "Response Type", y = "Response Count", fill = "Gender") +
  theme_minimal(base_size = 10) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 6),  
    legend.position = "bottom",
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 9, face = "bold"),
    legend.key.size = unit(0.4, "cm"),
    panel.grid.major.x = element_blank(),
    strip.text = element_text(size = 8, face = "bold"),
    strip.background = element_rect(fill = "gray90", color = "black"),
    panel.spacing = unit(1, "lines")
  )

```

The graph shows the distribution of responses to the `qc19` question across different countries, split by gender. In some countries, men tend to give a higher number of "Yes" responses, while women tend to answer "No" or "Don't Know" more frequently. This suggests that gender may influence how people answer the question in different regions.

In countries like Austria (AT), Great Britain (GB), and Spain (ES), responses are fairly balanced between genders. However, in countries such as Poland (PL) and Portugal (PT), one gender seems to dominate a particular response category, indicating a possible cultural or regional difference in how men and women approach the question.

Overall, Western European countries show more "Yes" responses, while Eastern European countries show higher proportions of "No" or "Don't Know" responses. These differences might be influenced by societal or cultural factors.

In conclusion, this graph highlights the role of both gender and cultural context in shaping responses to the same question across different countries. Understanding these differences could offer insights into the social and cultural dynamics at play.

```{r}
ggplot(qc19_country_gender_dist, aes(x = gender, y = count, fill = gender)) +
  geom_boxplot() +
  facet_wrap(~qc19) +  
  scale_fill_manual(values = c("Man" = "#3C8BFA", "Woman" = "#663CFA")) +
  labs(title = "Distribution of qc19 Responses by Gender",
       x = "Gender", y = "Response Count") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none")

```

**Distribution of qc19 Responses by Gender**

**(Preparing the data)** The qc19 variable was converted into a factor (as_factor(qc19)) to ensure categorical treatment.\
Gender was also converted into a factor (as_factor(d10)), making it easier to group responses by gender.\
The decision to visualize gender-based distribution ensures that any systematic differences between male and female responses are identified.

**(Interpretation)** This boxplot illustrates the response count distribution for qc19, separated by gender. We can see that women tend to have slightly higher counts across response categories (Yes, No, DK), as indicated by the median and interquartile range.\
The “DK” category shows a lower response count overall, with some outliers.\
The spread of responses is wider for Yes and No, indicating more variation in responses among men and women.

```{r}
data$isocntry <- reorder(data$isocntry, as.numeric(data$qc19), mean)  # Order by mean qc19 response

ggplot(data, aes(x = isocntry, y = as.numeric(qc19))) +
  geom_violin(width = 0.9, fill = "lightblue", color = "black") +  # Make violins wider
  geom_boxplot(width = 0.2, outlier.shape = NA) +  # Add boxplot overlay
  stat_summary(fun = mean, geom = "point", color = "red", size = 2) +  # Highlight means
  scale_y_continuous(breaks = c(1, 2, 3), labels = c("Yes", "No", "DK")) +
  labs(title = "Distribution of qc19 Responses by Country (Ordered by Mean)",
     x = "Country", y = "qc19 Response Score") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10),  # Adjust font size
      plot.title = element_text(size = 14, face = "bold")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

We selected this **violin plot** because it provides a detailed view of how responses to the `qc19` question are distributed across different countries, and it highlights gender-based differences clearly. The advantage of using a violin plot is that it not only shows the distribution of responses but also reveals the spread and density of the data. By combining it with a boxplot overlay, we could also display the median and interquartile range for each country, which adds another layer of insight into how responses vary.

In this plot, countries are ordered by the mean response score, which helps to compare countries based on their general tendency to answer the question. The red points highlighting the mean for each country provide a quick way to identify where each country stands in terms of overall response. This makes it easier to compare countries at a glance, much like the previous bar plot we used, but with more detailed distribution information.

While the previous bar plot helped us compare the responses between men and women across countries, this violin plot allows us to examine the distribution in more detail. In the bar plot, we could see that some countries had a higher count of "Yes" or "No" responses, but the violin plot provides a deeper understanding of how those responses are spread. For example, in some countries, the responses are tightly grouped around a specific value (like "Yes"), while in others, the responses are more spread out across "Yes", "No", and "DK".

From the graph, it’s clear that there are significant differences in the response distributions across countries. In some countries, the "Yes" response is much more common, while in others, "No" responses dominate. For example, in some Western European countries (such as the UK and Spain), the "Yes" response is more frequent, while in Eastern European countries (like Poland and Romania), "No" responses are higher. This suggests that cultural and societal factors in each country might influence how people answer such questions.

Another notable observation is the "Don't Know" (DK) category. In some countries, especially in Northern Europe (like Sweden), there’s a higher frequency of "Don't Know" responses. This could indicate that people in these countries are more uncertain or hesitant to provide a definitive answer.

Additionally, some countries have wider violin plots, which indicates that responses in those countries are more spread out, meaning people gave more varied answers. This could reflect a society with diverse opinions and viewpoints.

In conclusion, the differences across countries shed light on how cultural factors and societal norms influence responses to questions like this. Gender differences in responses also stand out in certain countries, suggesting that gender plays a significant role in how people answer, influenced by cultural and social contexts.

### title?

```{r}
# Step 1:  relevant columns from filtered_data
selected_data <- filtered_data |>
  select(c(
    "serialid", "d70", "d71_1", "d71_2", "d71_3", "d72_1", "d72_2", "polintr", "d10", "d25", "d1", "d63", "sd2_1", "sd2_2", "sd2_3", "sd2_4", "sd2_5", "sd2_6", "sd2_7", "sd3", "qc1_4", "qc1_8", "qc1_10", "d8r1", "d8r2", "d8", "qc19"))

# Step 2: relevant columns from `data`
country_data <- data |>
  select("serialid", "isocntry", "qc17_4", "qc17_3", "qc17_5")

colnames(trans_health_data) <- tolower(colnames(trans_health_data))
colnames(ilga_data) <- tolower(colnames(ilga_data))

edueco_data <- edueco_data |> 
  inner_join(trans_health_data, by= "country")

edueco_data <- edueco_data |> 
  inner_join(ilga_data, by= "country")

# Step 3: Merge country_data with edueco_data based on country codes
country_data <- country_data %>%
  inner_join(edueco_data, by = c("isocntry" = "iso2c"))

# Step 4: Merge selected_data with country_data using "serialid" as the key
merged_data <- selected_data %>%
  inner_join(country_data, by = "serialid")


merged_data <- merged_data |> rename(
  lifesat = d70,
  natmat = d71_1,
  eumat = d71_2,
  locmat = d71_3,
  euvoice = d72_1,
  natvoice = d72_2,
  gender = d10,
  community = d25,
  ideo = d1,
  class = d63,
  ethnic = sd2_1,
  skin = sd2_2,
  relig = sd2_3,
  roma = sd2_4,
  sex = sd2_5,
  disab = sd2_6,
  other = sd2_7,
  religion = sd3,
  sexdiscr = qc1_4,
  transdiscr = qc1_8,
  interdiscr = qc1_10,
  transgender_civil_dc = qc19,
  gdp = `NY.GDP.MKTP.CD`,
  edu_exp_pct = `SE.XPD.TOTL.GD.ZS`,
  preprim_exp = `PrePrimary (XSPENDP.02.FDPUB.FNCUR)`,
  prim_exp = `Primary (XSPENDP.1.FDPUB.FNCUR)`,
  lose_exp = `LowerSecondary (XSPENDP.2.FDPUB.FNCUR)`,
  upse_exp = `UpperSecondary (XSPENDP.2T3.FDPUB.FNCUR)`,
  ter_exp = `Tertiary (XSPENDP.3.FDPUB.FNCUR)`,
  voc_exp = `VocationalTraining (XSPENDP.4.FDPUB.FNCUR)`,
  school_div_sexual_orientation = qc17_3,
  school_div_transgender = qc17_4,
  school_div_intersex= qc17_5, 
  age_edu = d8,
  age_edu_5cat = d8r1,
  age_edu_11cat = d8r2,
  nolger = `no legal framework making legal gender recognition impossible`,
exist_lgme = `existence of legal measures`,
exist_adm = `existence of administrative procedures`,
name_change = `name change`,
nar_name_change = `no age restriction, name change`,
self_det = `self-determination`,
nb_recog = `non-binary recognition`,
psych_diag = `no 'gender identity disorder' diagnosis/psychological opinion required`,
med_interven = `no compulsory medical intervention required`,
surg_interven = `no compulsory surgical intervention required`,
steril_req = `no compulsory sterilisation required`,
div_req = `no compulsory divorce required`,
age_restrict = `no age restriction`,
lgrp_minors = `legal gender recognition procedures exist for minors`,
depath = `depathologisation`


)


merged_data<- merged_data |> 
  select(-c(x, isocntry, ...1))
  
  
merged_data <- merged_data |> select(country, iso3c, everything())



write.csv(merged_data, "final_data.csv", col.names = TRUE)

```

### ?? Added Variable

**GDP for Each Country**

Explain why GDP

```{r}

```

**Education Expenditures**

Explain why Education Expenditures

```{r}

```

## EXPLAINING CROSS-COUNTRY DIFFERENCES

In this section, we aim to identify factors influencing support for or opposition to transgender rights, particularly the ability to change civil documents. Our analysis will alternate between individual-level and country-level perspectives

## Descriptive Analysis

```{r}
final_data <-read_csv("data_cleaning_files/final_data.csv")

final_data<- final_data[, -1]
```

### Missing data imputation

```{r}
#numeric variables
summary(final_data)

```

```{r}
# Visualize missing values
gg_miss_var(final_data) +
  theme_minimal() +
  labs(title = "Missing Data Patterns")

```

In this analysis, we examined the missing data patterns in my dataset to assess data completeness and identify potential issues. The visualization helped determine which variables contain missing values and to what extent. While some variables were fully observed, others had significant gaps, requiring appropriate handling strategies.

```{r}
# Ensure final_data is a data frame
final_data <- as.data.frame(final_data)

# only variables with missing data for imputation
impute_vars <- final_data %>% select(`preprim_exp`, `prim_exp`, `lose_exp`, `upse_exp`, `voc_exp`)

# Generate a predictor matrix
predictorMatrix <- make.predictorMatrix(impute_vars)

imputed_data <- mice(impute_vars, method = "mean", m = 5, maxit = 10, seed = 123)

# Replace missing values with the first imputed dataset
final_data <- final_data %>%
  mutate(
    preprim_exp = complete(imputed_data, 1)$preprim_exp,
    prim_exp = complete(imputed_data, 1)$prim_exp,
    lose_exp = complete(imputed_data, 1)$lose_exp,
    upse_exp = complete(imputed_data, 1)$upse_exp,
    voc_exp = complete(imputed_data, 1)$voc_exp
  )

# Check if imputation worked correctly
summary(final_data$voc_exp)
summary(final_data$preprim_exp)
summary(final_data$prim_exp)
summary(final_data$lose_exp)
summary(final_data$upse_exp)

```

In this analysis, we handled missing data using mean imputation with the MICE package. This method replaces missing values with the average of observed values for each variable, preventing data loss while maintaining consistency. We focused on five education expenditure variables (preprim_exp, prim_exp, lose_exp, upse_exp, voc_exp), ensuring they no longer contain missing values.

After imputation, the summary statistics confirmed that all variables now have complete data, with reasonable mean and range values. However, since mean imputation can reduce variability, we need to check whether the data distribution has been affected. Notably, voc_exp has a minimum value of 0, unlike other variables with higher minimums, suggesting a different distribution pattern.

Overall, our imputation process successfully addressed missing data, making the dataset more reliable for further analysis. To ensure the imputed values align well with the data structure, we recommend additional visual checks, such as histograms or density plots.

```{r}
# Visualize missing values
gg_miss_var(final_data) +
  theme_minimal() +
  labs(title = "After Imputation, Missing Data Patterns")

```

The visualization confirms that after performing mean imputation, all missing values in the dataset have been successfully handled. The vertical bar at zero missing values indicates that no variables contain missing data anymore. This means our imputation process effectively filled in all gaps, making the dataset complete and ready for further analysis.

### **Descriptive Statistic: Individual level data**

```{r}
#  only individual-level variables
individual_vars <- final_data %>%
  select(gender, age_edu_5cat, age_edu_11cat, polintr, natvoice, euvoice, relig, 
         roma, skin, sexdiscr, transdiscr, school_div_transgender, 
         school_div_sexual_orientation, school_div_intersex, transgender_civil_dc)

```

We categorized survey variables into meaningful groups (e.g., Demographics, Identity, School Measures). Then, we reshaped the data into a long format and assigned clear labels for better interpretation. We created histograms to visualize the distribution of numerical variables and a bar chart to analyze categorical variables (e.g., gender). The workflow enhances data organization, clarity, and visualization for better insights.

```{r}
# Categorize Variables
categorize_variables <- function(var_name) {
  if (var_name %in% c("age_edu_5cat", "age_edu_11cat", "skin")) {
    return("Demographics")
  } else if (var_name %in% c("school_div_intersex", "school_div_sexual_orientation", "school_div_transgender")) {
    return("School Should Give Information Measures")
  } else if (var_name %in% c("natvoice", "euvoice")) {
    return("Voice Representation")
  } else if (var_name %in% c("relig", "roma")) {
    return("Identity")
  } else {
    return("Other Variables")
  }
}

# Prepare Data
improved_data <- individual_vars %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value") %>%
  mutate(
    Variable_Group = sapply(Variable, categorize_variables),
    Variable_Label = case_when(
      Variable == "age_edu_5cat" ~ "Age-Education (5 cat)",
      Variable == "age_edu_11cat" ~ "Age-Education (11 cat)",
      Variable == "skin" ~ "Skin Color",
      Variable == "school_div_intersex" ~ "School Diversity (Intersex)",
      Variable == "school_div_sexual_orientation" ~ "School Diversity (Sexual Orientation)",
      Variable == "school_div_transgender" ~ "School Diversity (Transgender)",
      Variable == "natvoice" ~ "Native Voice",
      Variable == "euvoice" ~ "European Voice",
      Variable == "polintr" ~ "Political Interest",
      Variable == "relig" ~ "Religion",
      Variable == "roma" ~ "Roma Identity",
      Variable == "sexdiscr" ~ "Sexual Discrimination",
      Variable == "transdiscr" ~ "Transgender Discrimination",
      TRUE ~ Variable
    )
  )

# Function for Histograms
create_improved_histogram <- function(data, group_name) {
  filtered_data <- data %>% filter(Variable_Group == group_name)
  
  ggplot(filtered_data, aes(x = Value, fill = after_stat(count))) +
    geom_histogram(bins = 15, color = "white", alpha = 0.9) +
    scale_fill_viridis(option = "D", name = "Count", direction = 1) +
    facet_wrap(~replace_na(Variable_Label, "Unknown"), scales = "free", ncol = 2) +
    labs(
      title = paste("Distribution of", group_name),
      x = "Value",
      y = "Frequency",
      caption = "Values shown as frequencies rather than percentages for better readability"
    ) +
    theme_minimal(base_size = 12) +
    theme(
      plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
      axis.title = element_text(size = 12, face = "bold"),
      axis.text.x = element_text(angle = 30, hjust = 1, size = 10),
      axis.text.y = element_text(size = 10),
      strip.text = element_text(size = 12, face = "bold"),
      strip.background = element_rect(fill = "lightgray", color = NA),
      panel.spacing = unit(1, "lines"),
      legend.position = "right",
      plot.margin = margin(10, 10, 10, 10, unit= "pt")
    )
}

# Generate Plots
demographics_plot <- create_improved_histogram(improved_data, "Demographics")
information_plot <- create_improved_histogram(improved_data, "School Should Give Information Measures")
voice_plot <- create_improved_histogram(improved_data, "Voice Representation")
identity_plot <- create_improved_histogram(improved_data, "Identity")
other_plot <- create_improved_histogram(improved_data, "Other Variables")

# Function for Bar Chart
create_bar_chart <- function(data, variable_name) {
  var_data <- individual_vars %>%
    select(all_of(variable_name)) %>%
    rename(Value = all_of(variable_name)) %>%
    group_by(Value) %>%
    summarize(Count = n()) %>%
    mutate(
      Percentage = Count / sum(Count) * 100,
      Value = factor(Value)
    )

  var_label <- improved_data %>%
    filter(Variable == variable_name) %>%
    pull(Variable_Label) %>%
    unique()

  if (length(var_label) == 0) {
    var_label <- variable_name
  }
  
  ggplot(var_data, aes(x = Value, y = Percentage, fill = Percentage)) +
    geom_bar(stat = "identity", width = 0.7) +
    geom_text(aes(label = sprintf("%.1f%%", Percentage)), position = position_stack(vjust = 0.5), color = "black") +
    scale_fill_viridis(option = "D") +
    labs(title = paste("Distribution of", var_label), x = "Category", y = "Percentage (%)") +
    theme_minimal()
}

gender_bar <- create_bar_chart(individual_vars, "gender")

```

#### Demographics: Age-Education Distribution Analysis

```{r}
demographics_plot
```

This variable categorizes individuals based on the age at which they completed full-time education. The dataset contains two versions: an **11-category classification** and a **simplified 5-category grouping**.

In the **detailed 11-category version**, respondents are categorized from **"Up to 14 years" (1) to "22 years and older" (9)**, alongside **"Still studying" (10)** and **"No full-time education" (11)**. The most common completion ages are **15 years (2) and 16 years (3)**, suggesting that a significant proportion of individuals exit full-time education during their teenage years. In contrast, fewer respondents remain in school past the age of 21.

The **simplified 5-category classification** merges some of these distinctions, grouping individuals as:\
- **"Up to 15 years" (1):** Those who left school by age 15.\
- **"16-19 years" (2):** Individuals who completed education in their late teens.\
- **"20 years and older" (3):** Those pursuing education beyond 19.\
- **"Still studying" (4):** Respondents currently in full-time education.\
- **"No full-time education" (5):** Individuals who never attended full-time education.

Across both classifications, the data highlights that **most individuals leave full-time education at 15 or 16 years old**, with fewer continuing beyond that. The presence of a **"Still studying"** category indicates an active student population, but the relatively low frequencies in higher education categories suggest that **early school leaving is prevalent**.

These findings offer insights into **educational attainment trends** and could be useful for **policymakers looking to improve retention in higher education**.

Additionally, The skin color variable helps categorize individuals based on whether they identify as a minority in terms of skin color. This distinction is crucial in understanding social dynamics, as it can provide insights into experiences of discrimination, representation, and equality within different groups.

The dataset includes two main categories. The first category (**0 - Not mentioned**) represents individuals who do not identify as part of a racial or ethnic minority based on their skin color. The second category (**1 - A minority in terms of skin color**) includes individuals who perceive themselves as belonging to a racial or ethnic minority group due to their skin tone.

The distribution of responses shows that the vast majority of individuals fall into the "Not mentioned" category, meaning they do not consider themselves as part of a skin color minority. In contrast, a much smaller proportion of respondents identify as belonging to a racial minority.

This finding suggests that racial or ethnic minorities based on skin color constitute a relatively small fraction of the dataset. Understanding this demographic breakdown is essential when examining disparities in economic opportunities, access to education, or social integration. Additionally, this variable can be used to investigate potential discrimination or differences in social perception based on racial identity.

#### School Diversity Attitudes

```{r}
 information_plot

```

The graph illustrates respondents' opinions on whether schools should provide education about diversity concerning intersex individuals, sexual orientation, and transgender identity. The response categories range from "Totally agree" (1) to "Totally disagree" (4), with an additional category for "Don't know" (5).

The results indicate that the majority of respondents either "Totally agree" (1) or "Tend to agree" (2) that schools should inform students about diversity in these areas. The highest agreement is observed across all three categories, suggesting broad support for diversity education. However, a notable proportion of respondents "Tend to disagree" (3) or "Totally disagree" (4), reflecting some resistance to integrating these topics into school curricula. Overall, the findings suggest that while most people recognize the importance of diversity education, there are still opposing views that indicate societal divisions on this issue.

#### Voice Representation

```{r}
voice_plot
```

The graph represents perceptions of voice representation in two contexts: at the European level ("European Voice") and at the national level ("Native Voice"). The responses are categorized into levels of agreement, ranging from "Totally agree" (1) to "Totally disagree" (4), with additional categories for refusals and unknown responses.

The data suggests that a significant portion of respondents "Tend to agree" (2) that their voice is heard both in their country and in the EU, making it the most common response. However, there are also notable groups that "Tend to disagree" (3) or "Totally disagree" (4), indicating skepticism about their influence in political or social discussions. The distribution is relatively similar for both European and national contexts, suggesting that perceptions of representation do not differ drastically between these two levels.

#### Identity

```{r}
identity_plot
```

The dataset analysis highlights how many people identify as religious or ethnic minorities. The graphs show that most individuals do not consider themselves part of these groups. In particular, only a small number identify as part of a religious minority, and the same goes for those who declare a Roma identity.

#### Gender

```{r}
gender_bar
```

According to the results, 54.7% of the respondents are female, while 45.3% are male. This indicates a slight overrepresentation of females in the survey compared to males. The relatively balanced distribution suggests that responses are not significantly skewed toward one gender, allowing for a more comprehensive analysis of gender-based trends and perspectives.

#### Other variables

```{r}
other_plot
```

##### Discrimination Based on Sexual Orientation and Gender Identity

Discrimination against individuals based on their **sexual orientation and gender identity** remains a significant issue across various societies. The survey categorizes public perceptions of discrimination into six levels: **Very widespread, Fairly widespread, Fairly rare, Very rare, Non-existent (Spontaneous), and Don’t know (DK)**. These categories help assess the extent to which individuals recognize discrimination in their respective countries.

The results indicate that **the majority of respondents perceive discrimination as either very or fairly widespread**. This suggests that LGBTQ+ individuals, particularly transgender people, continue to face systemic barriers in social, legal, and professional spheres. A smaller proportion of respondents consider discrimination **fairly rare or very rare**, implying regional differences in attitudes and legal frameworks that either mitigate or reinforce these experiences.

Interestingly, **very few respondents believe that discrimination does not exist at all**, reinforcing the notion that discrimination is a recognized issue, even in more progressive societies. Additionally, the presence of responses in the **"Don’t know" category** indicates a lack of awareness or reluctance to express opinions on this subject, which may be influenced by cultural sensitivities or personal biases.

Comparing discrimination against transgender individuals and sexual orientation-based discrimination, **the perception of discrimination against transgender individuals appears slightly higher**. This may stem from the additional social and legal barriers that transgender individuals face, including restrictions on gender recognition, healthcare access, and workplace inclusion.

These findings emphasize the need for **stronger anti-discrimination policies, legal protections, and social awareness initiatives** to ensure the fair treatment of LGBTQ+ individuals. Addressing these issues through education and policy reforms is crucial for fostering inclusive societies that respect and uphold the rights of all individuals, regardless of their gender identity or sexual orientation.

##### Political Interest

The Political Interest Index categorizes respondents into four levels: Strong (1), Medium (2), Low (3), and Not at all (4). The distribution shows that the majority of respondents fall into the Medium category, suggesting that most individuals engage with politics to some degree but do not exhibit strong interest. Meanwhile, fewer respondents report either strong political interest or no interest at all. This suggests a general trend toward moderate political engagement among participants.

### ??? Country-level economic variables (GDP per capita and unemployment)

```{r}

```

-----------------------------------------------------

## Statistical Model

```{r}

```

INDIVIDUAL LEVEL

**Gender** \## EVERYTHING FROM UNTIL OTHERWISE INDICATED CAN BE EDITED TO FIT OUR VARIABLE \##

```{r}


```

**Age**

```{r}

```

**Political_ideology**

*In political matters people talk of "the left" and "the right". How would you place your views on this scale?*

```{r}

```

**Religion_cat**

*Do you consider yourself to be…?*

```{r}


```

**Contact with transgender people (sd1_7)**

*Do you have friends or acquaintances who are transgender?*

```{r}


```

**Age when completing full-time education (d8)**

*How old were you when you stopped full‐time education?*

```{r}


```

**Personal economic situation (d60_ordinal)**

*During the last twelve months, would you say you had difficulties to pay your bills at the end of the month…?*

```{r}

```

**Sexual minority(sd2_5)**

*Where you live, do you consider yourself to be part of a sexual minority?*

```{r}


```

**Place of residence (type) (d25)**

*Would you say you live in a...?*

```{r}

```

**Equal rights for the LGB community (qc15_1_ordinal)**

```{r}


```

**Discrimination against the transgender community (qc1_8_ordinal)**

```{r}


```

COUNTRY LEVEL

**Variables created earlier country level.**

```{r}


```

**adp_general**

```{r}


```

**Country_name** \## END OF VARIABLE EDITS \##

```{r}


```

DATA FINAL COUNTRY

```{r}

```

DATA FINAL INDIVIDUAL

### Regression Analysis Individual Level

```{r}

```

### Multi-level analysis

```{r}

```

### Conclusion

## PREDICTION

Our goal is to develop a model capable of predicting support for transgender individuals changing civil documents. To accurately forecast our target variable, we must first establish a clear definition of the outcome we aim to predict.

### Models to Follow

```{r}

```

## References
